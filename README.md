# -Nonsinglet-distribution-functions-using-the-neural-network-and-genetic-algorithm
This repository contains the full implementation, data, and supplementary material
for the article:

Nonsinglet distribution functions using the neural network and genetic algorithm
_Submitted to European Physical Journal A (EPJ A)._

The project provides a hybrid numericalâ€“analytical framework for extracting
**nonsinglet PDFs** at LO, NLO, and NNLO using:

- Mellin-space analytical DGLAP evolution  
- Laguerre polynomial reconstruction in Bjorken-\(x\)  
- Neural network parameterization  
- Genetic Algorithm global optimization  


## ğŸ” **Overview of the Method**

The nonsinglet evolution equation is solved analytically in Mellin-\(N\) space:

\[
\frac{d q_{\text{NS}}(N,Q^2)}{d\ln Q^2}
 = \gamma_{\text{NS}}(N,\alpha_s) \, q_{\text{NS}}(N,Q^2),
\]

followed by inverse reconstruction using Laguerre polynomials:

\[
q(x,Q^2) = \sum_{n=0}^{N_L} a_n(Q^2) L_n(-\ln x).
\]

To ensure flexibility, the input distribution at the scale \( Q_0^2 \) is modeled by a neural network, and its parameters are optimized using a genetic algorithm
minimizing the global \(\chi^2\).

The framework supports three initial scales:

- \(Q_0^2 = 1\ \text{GeV}^2\)  
- \(Q_0^2 = 1.69\ \text{GeV}^2\)  
- \(Q_0^2 = 4\ \text{GeV}^2\)

---

 Purpose
This project is designed for fitting the parameters of the NNLO non-singlet DGLAP evolution model using a hybrid approach that combines a Genetic Algorithm (GA) and a three-layer Artificial Neural Network (ANN).

Using structure function data:(ğ‘¥,ğ‘„^2,ğ¹2ğ‘,ğ¹2ğ‘‘,ğ¹2ns), alongside the kinematic variables x and ğ‘„^2, the model retrieves the following parameters:ğ‘ğ‘¢,ğ‘ğ‘¢,ğ‘ğ‘¢,ğ‘‘ğ‘¢,ğ‘ğ‘‘,ğ‘ğ‘‘,ğ‘ğ‘‘,ğ‘‘ğ‘‘,Î›2

ğŸ“‚ Input Data
Main input file: The data used in this study correspond to the experimental measurements of the BCDMS, SLAC, NMC, H1,
and ZEUS collaborations
Columns:x, Q, Q^2, F2p, F2d, F2ns
The dataset represents simulated or experimental structure function values for proton, deuteron, and non-singlet channels, prepared at a chosen starting scale ğ‘„0^2 (default: 4 GeVÂ²).

âš™ï¸ Methodology
Data Preprocessing â€“ Load CSV and split into 80% training / 20% validation.
Surrogate Modeling with ANN â€“
Network architecture: [64, 64, 32] neurons in hidden layers.
Activation: tanh for hidden layers, linear for output.
Optimization with GA â€“
Population size: 219
Mutation rate: 0.05
Crossover rate: 0.80
Early stopping: stop after 50 generations with no improvement.
Fine-Tuning â€“ Locally improve GA solutions using the trained ANN.
Evaluation â€“ Compute ğ‘…^2 and RMSE for all channels.
Multi-Run Averaging â€“ Perform 30 independent runs to get mean Â± standard deviation.
ğŸ“Š Output Files
inverse_coefficients_hybrid_per_runs.csv â€“ Coefficients and ğ‘…^2 for each run.
ga_histories.csv â€“ Best fitness values over generations for each run.
inverse_coefficients_hybrid_results.csv â€“ Mean and standard deviation of coefficients across runs.
ğŸ”„ Changing ğ‘„0^2 
While most existing public repositories hard-code 
ğ‘„0^2=4GeV^2, this script allows you to make it a configurable parameter. Adjust the initial-scale filter in load_data() to match your desired ğ‘„0^2 and ensure downstream model functions use it consistently.

ğŸ“Œ Requirements
Python â‰¥ 3.9
TensorFlow â‰¥ 2.8
NumPy â‰¥ 1.20
Pandas â‰¥ 1.3
mpmath â‰¥ 1.3.0 (if exact NNLO forward evolution is enabled)
â± Runtime
On a standard CPU, a full 30-run hybrid GA+ANN execution may take between 30â€“60 minutes, depending on dataset size and hardware.

ğŸ§ª Citation
If you use this code in an academic publication, please cite the experimental data sources (BCDMS, SLAC, NMC, H1, ZEUS) and acknowledge this Hybrid GA+ANN implementation for NNLO DGLAP inverse modeling.txt
